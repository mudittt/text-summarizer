{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-21T15:31:15.302619Z","iopub.status.busy":"2024-03-21T15:31:15.302245Z","iopub.status.idle":"2024-03-21T15:31:54.134133Z","shell.execute_reply":"2024-03-21T15:31:54.133111Z","shell.execute_reply.started":"2024-03-21T15:31:15.302588Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-21 15:31:31.182940: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-21 15:31:31.183100: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-21 15:31:31.474648: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np \n","import pandas as pd \n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","from transformers import pipeline, set_seed\n","from datasets import load_dataset, load_from_disk, load_metric\n","import matplotlib.pyplot as plt\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","from tqdm import tqdm\n","import torch\n","nltk.download(\"punkt\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:32:01.162759Z","iopub.status.busy":"2024-03-21T15:32:01.161900Z","iopub.status.idle":"2024-03-21T15:32:14.015596Z","shell.execute_reply":"2024-03-21T15:32:14.014784Z","shell.execute_reply.started":"2024-03-21T15:32:01.162724Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe4559a0d4554a5c9920f9eece3cf254","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/300 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4777c40a4a164721868d02355f72483b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a5d7bac0cbf4ca586ed2b2e130bbe4b","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a9e1e25e61049dfb75c3bd6304f18f1","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d03cb846561749ea96674bd774e559e8","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"234a13b779984e178805c7a255f68102","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}],"source":["device = \"cuda\"\n","# model_ckpt = \"philschmid/bart-large-cnn-samsum\"\n","model_ckpt = \"google/pegasus-cnn_dailymail\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:32:16.050119Z","iopub.status.busy":"2024-03-21T15:32:16.049785Z","iopub.status.idle":"2024-03-21T15:32:19.029495Z","shell.execute_reply":"2024-03-21T15:32:19.028085Z","shell.execute_reply.started":"2024-03-21T15:32:16.050095Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-03-21 15:32:17--  https://github.com/mudittt/text-summarizer/raw/main/summarizer-data.zip\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mudittt/text-summarizer/main/summarizer-data.zip [following]\n","--2024-03-21 15:32:17--  https://raw.githubusercontent.com/mudittt/text-summarizer/main/summarizer-data.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7903594 (7.5M) [application/zip]\n","Saving to: 'summarizer-data.zip'\n","\n","summarizer-data.zip 100%[===================>]   7.54M  --.-KB/s    in 0.1s    \n","\n","2024-03-21 15:32:17 (76.4 MB/s) - 'summarizer-data.zip' saved [7903594/7903594]\n","\n","Archive:  summarizer-data.zip\n","  inflating: samsum-test.csv         \n","  inflating: samsum-train.csv        \n","  inflating: samsum-validation.csv   \n","   creating: samsum_dataset/\n"," extracting: samsum_dataset/dataset_dict.json  \n","   creating: samsum_dataset/test/\n","  inflating: samsum_dataset/test/data-00000-of-00001.arrow  \n","  inflating: samsum_dataset/test/dataset_info.json  \n","  inflating: samsum_dataset/test/state.json  \n","   creating: samsum_dataset/train/\n","  inflating: samsum_dataset/train/data-00000-of-00001.arrow  \n","  inflating: samsum_dataset/train/dataset_info.json  \n","  inflating: samsum_dataset/train/state.json  \n","   creating: samsum_dataset/validation/\n","  inflating: samsum_dataset/validation/data-00000-of-00001.arrow  \n","  inflating: samsum_dataset/validation/dataset_info.json  \n","  inflating: samsum_dataset/validation/state.json  \n"]}],"source":["!wget https://github.com/mudittt/text-summarizer/raw/main/summarizer-data.zip\n","!unzip summarizer-data.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:32:22.710382Z","iopub.status.busy":"2024-03-21T15:32:22.709439Z","iopub.status.idle":"2024-03-21T15:32:22.762551Z","shell.execute_reply":"2024-03-21T15:32:22.761514Z","shell.execute_reply.started":"2024-03-21T15:32:22.710345Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 14732\n","    })\n","    test: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 819\n","    })\n","    validation: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 818\n","    })\n","})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataset_samsum = load_from_disk('samsum_dataset')\n","dataset_samsum"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:32:24.837137Z","iopub.status.busy":"2024-03-21T15:32:24.836740Z","iopub.status.idle":"2024-03-21T15:32:24.846926Z","shell.execute_reply":"2024-03-21T15:32:24.846066Z","shell.execute_reply.started":"2024-03-21T15:32:24.837096Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Split lengths: [14732, 819, 818]\n","Features: ['id', 'dialogue', 'summary']\n","\n","Dialogue:\n","Eric: MACHINE!\n","Rob: That's so gr8!\n","Eric: I know! And shows how Americans see Russian ;)\n","Rob: And it's really funny!\n","Eric: I know! I especially like the train part!\n","Rob: Hahaha! No one talks to the machine like that!\n","Eric: Is this his only stand-up?\n","Rob: Idk. I'll check.\n","Eric: Sure.\n","Rob: Turns out no! There are some of his stand-ups on youtube.\n","Eric: Gr8! I'll watch them now!\n","Rob: Me too!\n","Eric: MACHINE!\n","Rob: MACHINE!\n","Eric: TTYL?\n","Rob: Sure :)\n","\n","Summary:\n","Eric and Rob are going to watch a stand-up on youtube.\n"]}],"source":["split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n","\n","print(f\"Split lengths: {split_lengths}\")\n","print(f\"Features: {dataset_samsum['train'].column_names}\")\n","print(\"\\nDialogue:\")\n","\n","print(dataset_samsum[\"test\"][1][\"dialogue\"])\n","\n","print(\"\\nSummary:\")\n","print(dataset_samsum[\"test\"][1][\"summary\"])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:32:28.013047Z","iopub.status.busy":"2024-03-21T15:32:28.012659Z","iopub.status.idle":"2024-03-21T15:32:28.019112Z","shell.execute_reply":"2024-03-21T15:32:28.018061Z","shell.execute_reply.started":"2024-03-21T15:32:28.013017Z"},"trusted":true},"outputs":[],"source":["def convert_examples_to_features(example_batch):\n","    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n","\n","    with tokenizer.as_target_tokenizer():\n","        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n","\n","    return {\n","        'input_ids' : input_encodings['input_ids'],\n","        'attention_mask': input_encodings['attention_mask'],\n","        'labels': target_encodings['input_ids']\n","    }"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:32:30.191250Z","iopub.status.busy":"2024-03-21T15:32:30.190351Z","iopub.status.idle":"2024-03-21T15:32:38.870616Z","shell.execute_reply":"2024-03-21T15:32:38.869829Z","shell.execute_reply.started":"2024-03-21T15:32:30.191202Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4b966c0c11d4841b9618d68b95739e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/15 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"010b10f04ace4fc7a5c7e800464931bd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84faf30aa56d431f9a17037e844d2ddc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:32:38.872434Z","iopub.status.busy":"2024-03-21T15:32:38.872130Z","iopub.status.idle":"2024-03-21T15:32:38.878353Z","shell.execute_reply":"2024-03-21T15:32:38.877441Z","shell.execute_reply.started":"2024-03-21T15:32:38.872410Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 14732\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dataset_samsum_pt[\"train\"]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:32:43.294637Z","iopub.status.busy":"2024-03-21T15:32:43.293919Z","iopub.status.idle":"2024-03-21T15:32:43.299583Z","shell.execute_reply":"2024-03-21T15:32:43.298371Z","shell.execute_reply.started":"2024-03-21T15:32:43.294600Z"},"trusted":true},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","\n","seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:33:20.051489Z","iopub.status.busy":"2024-03-21T15:33:20.050547Z","iopub.status.idle":"2024-03-21T15:33:20.059370Z","shell.execute_reply":"2024-03-21T15:33:20.058430Z","shell.execute_reply.started":"2024-03-21T15:33:20.051456Z"},"trusted":true},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","# for name, param in model_pegasus.named_parameters():\n","#     if not name.startswith(\"model.encoder.layers.0\") and not name.startswith(\"model.decoder.layers\") and param.requires_grad:\n","#         param.requires_grad = False\n","\n","trainer_args = TrainingArguments(\n","    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n","    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n","    weight_decay=0.01, logging_steps=10,\n","    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n","    gradient_accumulation_steps=32\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:33:21.716289Z","iopub.status.busy":"2024-03-21T15:33:21.715453Z","iopub.status.idle":"2024-03-21T15:33:23.330044Z","shell.execute_reply":"2024-03-21T15:33:23.329134Z","shell.execute_reply.started":"2024-03-21T15:33:21.716258Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["trainer = Trainer(model=model_pegasus, args=trainer_args,\n","                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n","                  train_dataset=dataset_samsum_pt[\"train\"],\n","                  eval_dataset=dataset_samsum_pt[\"validation\"])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:33:29.452202Z","iopub.status.busy":"2024-03-21T15:33:29.451579Z","iopub.status.idle":"2024-03-21T16:30:33.744278Z","shell.execute_reply":"2024-03-21T16:30:33.743312Z","shell.execute_reply.started":"2024-03-21T15:33:29.452171Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240321_153342-75dy4008</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/momomomofast/huggingface/runs/75dy4008' target=\"_blank\">stellar-water-2</a></strong> to <a href='https://wandb.ai/momomomofast/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/momomomofast/huggingface' target=\"_blank\">https://wandb.ai/momomomofast/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/momomomofast/huggingface/runs/75dy4008' target=\"_blank\">https://wandb.ai/momomomofast/huggingface/runs/75dy4008</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [230/230 55:59, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=230, training_loss=0.8804967590000319, metrics={'train_runtime': 3423.8921, 'train_samples_per_second': 4.303, 'train_steps_per_second': 0.067, 'total_flos': 6795714120007680.0, 'train_loss': 0.8804967590000319, 'epoch': 1.0})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T16:30:58.677889Z","iopub.status.busy":"2024-03-21T16:30:58.677469Z","iopub.status.idle":"2024-03-21T16:30:58.693630Z","shell.execute_reply":"2024-03-21T16:30:58.692539Z","shell.execute_reply.started":"2024-03-21T16:30:58.677838Z"},"trusted":true},"outputs":[],"source":["def generate_batch_sized_chunks(list_of_elements, batch_size):\n","    \"\"\"split the dataset into smaller batches that we can process simultaneously\n","    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n","    for i in range(0, len(list_of_elements), batch_size):\n","        yield list_of_elements[i : i + batch_size]\n","\n","\n","\n","def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n","                               batch_size=16, device=device,\n","                               column_text=\"article\",\n","                               column_summary=\"highlights\"):\n","    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n","    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n","\n","    for article_batch, target_batch in tqdm(\n","        zip(article_batches, target_batches), total=len(article_batches)):\n","\n","        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n","                        padding=\"max_length\", return_tensors=\"pt\")\n","\n","        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n","                         attention_mask=inputs[\"attention_mask\"].to(device),\n","                         length_penalty=0.8, num_beams=8, max_length=128)\n","        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n","\n","        # Finally, we decode the generated texts,\n","        # replace the  token, and add the decoded texts with the references to the metric.\n","        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n","                                clean_up_tokenization_spaces=True)\n","               for s in summaries]\n","\n","        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n","\n","\n","        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n","\n","    #  Finally compute and return the ROUGE scores.\n","    score = metric.compute()\n","    return score\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T16:31:03.117418Z","iopub.status.busy":"2024-03-21T16:31:03.116313Z","iopub.status.idle":"2024-03-21T16:31:20.233627Z","shell.execute_reply":"2024-03-21T16:31:20.232418Z","shell.execute_reply.started":"2024-03-21T16:31:03.117379Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=bba0f0095e203229cf746739ec204d5fd1ddf2d0dc878793b02e7ac2aa7923d8\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]}],"source":["!pip install rouge-score "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T16:31:20.236023Z","iopub.status.busy":"2024-03-21T16:31:20.235726Z","iopub.status.idle":"2024-03-21T16:31:20.653253Z","shell.execute_reply":"2024-03-21T16:31:20.652252Z","shell.execute_reply.started":"2024-03-21T16:31:20.235996Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d291073650f4c5ba67cb4437a3ee145","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n","rouge_metric = load_metric('rouge')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T16:31:29.046944Z","iopub.status.busy":"2024-03-21T16:31:29.046011Z","iopub.status.idle":"2024-03-21T16:48:41.787382Z","shell.execute_reply":"2024-03-21T16:48:41.785973Z","shell.execute_reply.started":"2024-03-21T16:31:29.046906Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 410/410 [17:07<00:00,  2.51s/it]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>rougeLsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pegasus</th>\n","      <td>0.012667</td>\n","      <td>0.000241</td>\n","      <td>0.012625</td>\n","      <td>0.01265</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           rouge1    rouge2    rougeL  rougeLsum\n","pegasus  0.012667  0.000241  0.012625    0.01265"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["score = calculate_metric_on_test_ds(\n","    dataset_samsum['test'], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",")\n","\n","rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n","\n","pd.DataFrame(rouge_dict, index = [f'pegasus'] )"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T16:49:51.880132Z","iopub.status.busy":"2024-03-21T16:49:51.879375Z","iopub.status.idle":"2024-03-21T16:49:54.976158Z","shell.execute_reply":"2024-03-21T16:49:54.975049Z","shell.execute_reply.started":"2024-03-21T16:49:51.880099Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"]}],"source":["model_pegasus.save_pretrained(\"pegasus-samsum-model\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T16:49:48.244103Z","iopub.status.busy":"2024-03-21T16:49:48.243360Z","iopub.status.idle":"2024-03-21T16:49:48.318136Z","shell.execute_reply":"2024-03-21T16:49:48.317081Z","shell.execute_reply.started":"2024-03-21T16:49:48.244069Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('tokenizer/tokenizer_config.json',\n"," 'tokenizer/special_tokens_map.json',\n"," 'tokenizer/vocab.json',\n"," 'tokenizer/merges.txt',\n"," 'tokenizer/added_tokens.json',\n"," 'tokenizer/tokenizer.json')"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.save_pretrained(\"tokenizer\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T17:09:45.111452Z","iopub.status.busy":"2024-03-21T17:09:45.110886Z","iopub.status.idle":"2024-03-21T17:09:45.206498Z","shell.execute_reply":"2024-03-21T17:09:45.205532Z","shell.execute_reply.started":"2024-03-21T17:09:45.111417Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"/content/tokenizer\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T17:09:49.921384Z","iopub.status.busy":"2024-03-21T17:09:49.920652Z","iopub.status.idle":"2024-03-21T17:10:01.633414Z","shell.execute_reply":"2024-03-21T17:10:01.632108Z","shell.execute_reply.started":"2024-03-21T17:09:49.921353Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Your max_length is set to 128, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n"]},{"name":"stdout","output_type":"stream","text":["Dialogue:\n","Neville: Hi there, does anyone remember what date I got married on?\n","Don: Are you serious?\n","Neville: Dead serious. We're on vacation, and Tina's mad at me about something. I have a strange suspicion that this might have something to do with our wedding anniversary, but I have nowhere to check.\n","Wyatt: Hang on, I'll ask my wife.\n","Don: Haha, someone's in a lot of trouble :D\n","Wyatt: September 17. I hope you remember the year ;)\n","\n","Reference Summary:\n","Wyatt reminds Neville his wedding anniversary is on the 17th of September. Neville's wife is upset and it might be because Neville forgot about their anniversary.\n","\n","Model Summary:\n","Neville and Tina are on vacation. Neville's wife is mad at him. Neville got married on September 17th. Wyatt will ask his wife if she remembers the date. Neville has a strange suspicion that it might have something to do with their wedding anniversary.\n"]}],"source":["\n","gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n","\n","\n","\n","sample_text = dataset_samsum[\"train\"][5][\"dialogue\"]\n","\n","reference = dataset_samsum[\"train\"][5][\"summary\"]\n","\n","pipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\",tokenizer=tokenizer)\n","\n","##\n","print(\"Dialogue:\")\n","print(sample_text)\n","\n","\n","print(\"\\nReference Summary:\")\n","print(reference)\n","\n","\n","print(\"\\nModel Summary:\")\n","print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":4}
